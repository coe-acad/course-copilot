{
    "id": "mark-scheme",
    "prompt": "You are given a variable called question_paper_text./nThis variable refers to the full question paper./nDo NOT echo or restate it./n/nFor each question, assign marks as given in the question paper, either given in brackets or against each question. Generate a numbered Scheme of Evaluation in the following format for ALL the questions in question_paper_text.:/n/nFor each question, output exactly these three sections:/nQuestion number/nQuestion text — copy each question verbatim from question_paper_text. If truncated or illegible, append “(incomplete in source)” at the end./nAnswer template — bullet the minimum core ideas (or clear equivalents) in strict logical order needed for full credit. Use short, precise bullets. If a single correct answer is unambiguous (value/option/etc.), state it explicitly./nMarking scheme (Total = max_marks) — one bullet per core idea, labeled A, B, C in the same order as the Answer template. After each label, put the marks in square brackets, e.g. A [2], then a terse description of the expectation in context. Strictly limit the number of bullets to three./n/nThe marks on A+B+C must sum exactly to max_marks printed in the paper. Ensure there are no errors in this. Recheck the marking scheme if required./n/nInteger-only per-bullet marks: The number inside each square bracket [ ] must be an integer (digits only)—no decimals/fractions (e.g., no [0.5], [1.0], ½). If finer granularity seems needed, restructure by confining to the most essential bullets in the answer./n/nMini-example (for a 5-mark item)/nMarking scheme (Total = 5)/nA [2]: states/defines core principle in this context/nB [2]: applies principle correctly to the given setup/nC [1]: computes/states final result with correct units/justification/n/nIMPORTANT: your only output must be a single JSON object (for single questions) or a JSON array of such objects (for batch), each with these keys:/nQuestion number/nQuestion text/nAnswer template/nMarking scheme/n/nNow generate a JSON array of mark-scheme objects for all questions in question_paper_text. Each object must have all the keys listed above./n/nMake sure you use only the file question_paper_text and give the response for all the questions in the question paper. Maintain the same question order as in question_paper_text. If a question has sub-parts, keep a single JSON object for the whole question; do not split into ‘2(a)’, ‘2(b)’. Handle marks via bullets as per Sub-question handling./n/n Before giving the final output, please check once again whether your generated content contains the mark scheme for ALL the questions. If it does not, please regenerate the mark scheme afresh based on the instructions in this prompt. /n/nRequired_input_variables/nQuestion paper: {{extracted_questions}}",
    "required_input_variables": ["extracted_questions"]
}
